# ğŸš€ ChatGPT Clone BY Anas â€” Full Stack AI Chat Application

A fully-functional ChatGPT-like clone built with:
- ğŸ›¡ï¸ **Authentication Backend** â€” FastAPI
- ğŸ¤– **Chat Backend with LLM API Integration** â€” FastAPI
- ğŸ¨ **Frontend Interface** â€” Streamlit
- ğŸ“¬ **Notifications via RabbitMQ**
- ğŸ—„ï¸ **Redis & PostgreSQL** for session and persistent storage

---

## ğŸ“Œ Table of Contents
- [Project Overview](#project-overview)
- [Tech Stack](#tech-stack)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Setup & Installation](#setup--installation)
- [Backend Services](#backend-services)
  - [Authentication Backend](#authentication-backend)
  - [Chat Backend](#chat-backend)
- [Frontend](#frontend)
- [Database](#database)
- [Message Queue (RabbitMQ)](#message-queue-rabbitmq)
- [Environment Variables](#environment-variables)
- [Features](#features)
- [Future Improvements](#future-improvements)
- [Contributors](#contributors)

---

## ğŸ“Œ Project Overview
This project is a **ChatGPT-inspired full-stack application** featuring:
- Secure user **authentication and authorization**
- A **chat interface** that interacts with an LLM API like OpenAI or DeepSeek
- **Session management** with Redis
- Persistent **chat history stored in PostgreSQL**
- **Background notifications** triggered via RabbitMQ (like sending a "Congratulations" message on successful registration)

---

## ğŸ“Œ Tech Stack

| Layer          | Technology               |
| -------------- | ------------------------ |
| Frontend       | Streamlit                |
| Chat Backend   | FastAPI, LLM API (e.g., OpenAI, DeepSeek) |
| Auth Backend   | FastAPI, JWT for authentication |
| Databases      | PostgreSQL, Redis        |
| Message Queue  | RabbitMQ + Pika          |
| Background Jobs| Celery (optional future addition) |

---
## ğŸ“Œ Architecture

```text
User (Frontend - Streamlit)
        |
        v
Authentication Backend
        |
        +--> PostgreSQL (User DB)
        |
        v
Message Queue (RabbitMQ)
        |
        v
Notification: "Congratulations on Registration!"
        |
        v
Chat Backend (LLM API Integration)
        |
        +--> PostgreSQL (Chat History)
        |
        +--> Redis (Session Cache)
```


---

## ğŸ“Œ Project Structure

```bash
ChatGPT-Clone/
â”‚
â”œâ”€â”€ backend_auth/     # Auth service with FastAPI & JWT
â”œâ”€â”€ chat_backend/     # Chat service with FastAPI & LLM API
â”œâ”€â”€ frontend/         # Streamlit frontend
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ“Œ Project Structure

```bash
ChatGPT-Clone/
â”‚
â”œâ”€â”€ backend_auth/     # Auth service with FastAPI & JWT
â”œâ”€â”€ chat_backend/     # Chat service with FastAPI & LLM API
â”œâ”€â”€ frontend/         # Streamlit frontend
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ“Œ Setup & Installation

### 1. Clone Repository
```bash
git clone https://github.com/MuhammadAnas1010/ChatGPT-Clone.git
cd ChatGPT-Clone
```

### 2. Install Dependencies
Each folder (`backend_auth`, `chat_backend`, `frontend`) has its own `requirements.txt` file. Activate virtual environments accordingly.

For example:
```bash
cd backend_auth
pip install -r requirements.txt
```

Repeat for `chat_backend` and `frontend`.

---

## ğŸ“Œ Backend Services

### ğŸ” Authentication Backend
- Built with **FastAPI**
- Provides:
  - User registration
  - Login & JWT Token generation
  - Protected endpoints with JWT verification
- On successful registration, **pushes a congratulation notification via RabbitMQ** to the message queue.

Start the auth backend:
```bash
uvicorn main:app --reload
```

---

### ğŸ§  Chat Backend
- Built on **FastAPI**
- Communicates with **OpenAI/DeepSeek** API for generating chat responses.
- Uses:
  - **Redis** to cache active sessions
  - **PostgreSQL** to store chat history permanently
- Provides endpoints to:
  - Send chat messages
  - Resume previous chats

Start the chat backend:
```bash
uvicorn main:app --reload
```

---

## ğŸ“Œ Frontend
- Built with **Streamlit**
- Features:
  - User authentication
  - Chat interface
  - View and resume previous chat history
- Communicates with both **auth backend** and **chat backend**.

Start the frontend:
```bash
cd frontend
streamlit run app.py
```

---

## ğŸ“Œ Database
- **PostgreSQL**
  - Stores users, hashed passwords, and chat history.
- **Redis**
  - Caches active chat sessions for quick access.

---

## ğŸ“Œ Message Queue (RabbitMQ)
- Used to **push a background notification ("Congratulations on Registering!")** when a new user signs up.
- Integrated via **Pika library** in Python.

RabbitMQ must be running locally:
```bash
# Linux
sudo systemctl start rabbitmq-server

# Docker
docker run -d --hostname my-rabbit --name some-rabbit -p 5672:5672 rabbitmq:3
```

---

## ğŸ“Œ Environment Variables
Each service uses `.env` files for sensitive configs:

```
POSTGRES_URL=postgresql://user:password@localhost/dbname
REDIS_URL=redis://localhost:6379
JWT_SECRET=your_secret
OPENAI_API_KEY=your_openai_api_key
RABBITMQ_URL=amqp://localhost
```

---

## ğŸ“Œ Features

âœ… User Registration & Login (JWT)  
âœ… Chat with LLM API (OpenAI/DeepSeek)  
âœ… Persistent chat history  
âœ… Resume previous sessions  
âœ… Background notification via RabbitMQ  
âœ… Redis session caching  
âœ… Streamlit-based UI

---

## ğŸ“Œ Future Improvements
- Add **WebSockets** for real-time chat.
- Integrate **Celery** with RabbitMQ for scalable background task handling.
- Add UI enhancements and analytics.
- Deploy entire stack via **Docker Compose**.

---

## ğŸ“Œ Contributors
- **Muhammad Anas** â€” Developer & Architect

---

## ğŸ“Œ License
This project is open-source and available under the MIT License.

---
